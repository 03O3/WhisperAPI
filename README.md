# Whisper Микросервисная Архитектура

Распознавание речи с использованием модели Whisper от OpenAI, реализованное в виде двух микросервисов:
- Python сервис для работы с Whisper API
- Golang клиент и веб-интерфейс

## Архитектура

Проект разделен на два микросервиса:

1. **Python Whisper Service**
   - Низкоуровневая работа с моделью Whisper
   - Эффективное управление моделями (кэширование)
   - TCP сервер для взаимодействия с клиентами

2. **Golang Web Service**
   - Веб-интерфейс для конечных пользователей
   - REST API для интеграции с другими системами
   - Эффективный клиент для Python сервиса

Микросервисы взаимодействуют по бинарному протоколу через TCP соединение.

## Установка и запуск

### Требования

1. Python 3.8-3.11
2. Go 1.18+
3. FFmpeg

### Python сервис

```bash
cd python
pip install -r requirements.txt
python whisper_service.py
```

По умолчанию сервис запускается на `127.0.0.1:9000`. Можно изменить через переменные окружения:
```bash
WHISPER_HOST=0.0.0.0 WHISPER_PORT=9001 python whisper_service.py
```

### Golang сервис

```bash
cd golang
go mod download
go run main.go whisper_client.go
```

По умолчанию веб-сервер запускается на порту 8080. Настройки через переменные окружения:
```bash
WHISPER_HOST=127.0.0.1 WHISPER_PORT=9000 SERVER_PORT=8080 go run main.go whisper_client.go
```

## API Endpoints

### REST API (Golang сервис)

#### GET /api/models
Получение списка доступных моделей.

#### POST /api/transcribe
Отправка аудиофайла для распознавания.

**Параметры:**
- `file`: Аудиофайл (multipart/form-data)
- `model`: Название модели (опционально, по умолчанию "base")
- `language`: Код языка (опционально)
- `task`: Задача - "transcribe" или "translate" (опционально, по умолчанию "transcribe")

#### GET /api/health
Проверка статуса сервиса.

## Протокол взаимодействия микросервисов

Микросервисы используют бинарный протокол поверх TCP со следующей структурой:

1. Заголовок (8 байт) - длина сообщения в формате big-endian
2. Тело сообщения - JSON данные

Команды:
- `transcribe` - распознавание речи
- `list_models` - получение списка моделей

## Доступные модели

- `tiny`: самая быстрая, но наименее точная модель (~1 ГБ)
- `base`: хороший баланс между скоростью и точностью (~1 ГБ)
- `small`: более точная, чем base, но медленнее (~2 ГБ)
- `medium`: еще более точная, но требует больше ресурсов (~5 ГБ)
- `large`: самая точная и самая ресурсоемкая модель (~10 ГБ)

При первом запуске модель будет загружена из интернета и кэширована локально.

## Устранение проблем

### Проблемы с Python 3.13

На Python 3.13 могут возникать ошибки при установке Whisper. Это связано с изменениями в Python и тем, что библиотека еще не полностью адаптирована к новым версиям.

Решения:
- Используйте Python 3.8-3.11
- Создайте виртуальное окружение с более старой версией Python
- Используйте conda для управления окружением

### Ошибки при установке через pip

Если вы видите ошибки при установке через requirements.txt:

1. Попробуйте использовать virtualenv или conda для создания изолированного окружения
2. Обновите pip до последней версии: `python -m pip install --upgrade pip`
3. Установите необходимые инструменты для сборки: `pip install setuptools wheel`
4. Установите Whisper напрямую из GitHub:

```bash
pip install git+https://github.com/openai/whisper.git
``` 