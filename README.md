# Whisper Микросервисная Архитектура

Распознавание речи с использованием модели Whisper от OpenAI, реализованное в виде двух микросервисов:
- Python сервис для работы с Whisper API
- Golang клиент и веб-интерфейс

## Архитектура

Проект разделен на два микросервиса:

1. **Python Whisper Service**
   - Низкоуровневая работа с моделью Whisper
   - Эффективное управление моделями (кэширование)
   - TCP сервер для взаимодействия с клиентами
   - Поддержка GPU через CUDA
   - Voice Activity Detection (VAD) фильтр

2. **Golang Web Service**
   - Веб-интерфейс для конечных пользователей
   - REST API для интеграции с другими системами
   - Эффективный клиент для Python сервиса
   - Метрики и мониторинг
   - Поддержка контекста для отмены операций

Микросервисы взаимодействуют по бинарному протоколу через TCP соединение.

## Установка и запуск

### Требования

1. Python 3.8-3.11
2. Go 1.18+
3. FFmpeg
4. CUDA Toolkit 11.8
5. PyTorch с поддержкой CUDA

### Python сервис

1. Установите Python 3.8-3.11 (рекомендуется):
   - [Python 3.11](https://www.python.org/downloads/release/python-3110/)

2. Установите CUDA Toolkit 11.8:
   - [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-11-8-0-download-archive)
   - При установке выберите опцию "Custom" и убедитесь, что выбраны компоненты:
     - CUDA Runtime
     - CUDA Development
     - cuBLAS
     - cuDNN

3. Установите PyTorch с поддержкой CUDA:
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

4. Установите необходимые библиотеки:
```bash
cd python
pip install -r requirements.txt
```

5. Установите библиотеки CUDA:
   - Скачайте библиотеки CUDA 11.8 из [репозитория](https://github.com/Purfview/whisper-standalone-win/releases/tag/libs)
   - Распакуйте архив `CUDA11_v4`
   - Скопируйте файлы в папку `C:\Windows\System32\`:
     - `cublas64_11.dll`
     - `cudnn64_8.dll`
     - и другие файлы из архива

6. Запустите сервис:
```bash
python whisper_service.py
```

По умолчанию сервис запускается на `127.0.0.1:9000`. Можно изменить через переменные окружения:
```bash
WHISPER_HOST=0.0.0.0 WHISPER_PORT=9001 python whisper_service.py
```

### Golang сервис

1. Установите Go 1.18 или выше:
   - [Go Downloads](https://golang.org/dl/)

2. Установите зависимости и запустите сервис:
```bash
cd golang
go mod download
go run main.go whisper_client.go
```

По умолчанию веб-сервер запускается на порту 8080. Настройки через переменные окружения:
```bash
WHISPER_HOST=127.0.0.1 WHISPER_PORT=9000 SERVER_PORT=8080 go run main.go whisper_client.go
```

## API Endpoints

### REST API (Golang сервис)

#### GET /api/models
Получение списка доступных моделей.

#### POST /api/transcribe
Отправка аудиофайла для распознавания.

**Параметры:**
- `file`: Аудиофайл (multipart/form-data)
- `model`: Название модели (опционально, по умолчанию "base")
- `language`: Код языка (опционально)
- `task`: Задача - "transcribe" или "translate" (опционально, по умолчанию "transcribe")

#### GET /api/health
Проверка статуса сервиса.

#### GET /api/metrics
Получение метрик сервиса.

## Протокол взаимодействия микросервисов

Микросервисы используют бинарный протокол поверх TCP со следующей структурой:

1. Заголовок (8 байт) - длина сообщения в формате big-endian
2. Тело сообщения - JSON данные

Команды:
- `transcribe` - распознавание речи
- `list_models` - получение списка моделей

## Доступные модели

- `tiny`: самая быстрая, но наименее точная модель (~1 ГБ)
- `base`: хороший баланс между скоростью и точностью (~1 ГБ)
- `small`: более точная, чем base, но медленнее (~2 ГБ)
- `medium`: еще более точная, но требует больше ресурсов (~5 ГБ)
- `large`: самая точная и самая ресурсоемкая модель (~10 ГБ)

При первом запуске модель будет загружена из интернета и кэширована локально.

## Устранение проблем

### Проблемы с Python 3.13

На Python 3.13 могут возникать ошибки при установке Whisper. Это связано с изменениями в Python и тем, что библиотека еще не полностью адаптирована к новым версиям.

Решения:
- Используйте Python 3.8-3.11
- Создайте виртуальное окружение с более старой версией Python
- Используйте conda для управления окружением

### Ошибки при установке через pip

Если вы видите ошибки при установке через requirements.txt:

1. Попробуйте использовать virtualenv или conda для создания изолированного окружения
2. Обновите pip до последней версии: `python -m pip install --upgrade pip`
3. Установите необходимые инструменты для сборки: `pip install setuptools wheel`
4. Установите Whisper напрямую из GitHub:

```bash
pip install git+https://github.com/openai/whisper.git
```

### Проблемы с CUDA

Если возникают ошибки, связанные с CUDA:

1. Убедитесь, что установлена правильная версия CUDA Toolkit (11.8)
2. Проверьте, что все необходимые DLL файлы скопированы в System32
3. Убедитесь, что PyTorch установлен с поддержкой CUDA
4. Проверьте, что GPU доступен и поддерживает CUDA

## Оптимизация

Для лучшей производительности:
1. Используйте GPU, если он доступен
2. Выберите подходящую модель в зависимости от требований к точности и скорости
3. Настройте параметры VAD фильтра под ваши нужды
4. Используйте кэширование моделей
5. Оптимизируйте размер буфера для аудио данных

## Лицензия

MIT License - смотрите файл [LICENSE](LICENSE)

## Вклад в проект

Приветствуются pull requests и issue reports. Для крупных изменений, пожалуйста, сначала откройте issue для обсуждения предлагаемых изменений.

## Тестирование

### Производительность

Были проведены тесты с различными моделями на аудиофайле длительностью 19:19:

#### Модель Small
- Время обработки: ~63 секунды
- Использование VAD фильтра: удалено 1:30 тишины
- Определение языка: русский (точность 98%)
- Использование GPU: CUDA
- Потребление памяти: ~2 ГБ

#### Модель Medium
- Время обработки: ~141 секунд (2:21)
- Использование VAD фильтра: удалено 1:30 тишины
- Определение языка: русский (точность 100%)
- Использование GPU: CUDA
- Потребление памяти: ~5 ГБ

#### Сравнение моделей
| Модель | Размер | Время обработки | Качество | Память | Точность определения языка |
|--------|--------|----------------|----------|--------|---------------------------|
| Tiny   | ~1 ГБ  | ~30 сек        | Низкое   | ~1 ГБ  | ~95%                      |
| Base   | ~1 ГБ  | ~60 сек        | Среднее  | ~1 ГБ  | ~97%                      |
| Small  | ~2 ГБ  | ~63 сек        | Хорошее  | ~2 ГБ  | ~98%                      |
| Medium | ~5 ГБ  | ~140 сек       | Отличное | ~5 ГБ  | ~100%                     |
| Large  | ~10 ГБ | ~300 сек       | Лучшее   | ~10 ГБ | ~100%                     |

### Рекомендации по выбору модели

1. **Tiny** - для быстрого тестирования и коротких аудиофайлов
2. **Base** - хороший баланс между скоростью и качеством
3. **Small** - оптимальный выбор для большинства задач (хорошее качество при разумном времени обработки)
4. **Medium** - для профессионального использования, когда важна точность
5. **Large** - для максимальной точности, когда время обработки не критично

### Оптимизация производительности

1. Используйте VAD фильтр для удаления тишины (экономия ~8% времени обработки)
2. Выбирайте модель в зависимости от требований к качеству и времени
3. Убедитесь, что у вас достаточно GPU памяти
4. Для больших файлов рекомендуется использовать модели Tiny или Base
5. Модель Small показала лучший баланс между скоростью и качеством для большинства задач